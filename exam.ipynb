{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n",
      "Installing missing packages: {'pointpats', 'libpysal', 'osmnx', 'contextily', 'esda', 'geopandas'}\n",
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# List of required packages (use package names as recognized by pip)\n",
    "required = {\n",
    "    'geopandas',\n",
    "    'osmnx',\n",
    "    'contextily',\n",
    "    'libpysal',\n",
    "    'esda',\n",
    "    'pointpats',\n",
    "    'matplotlib',\n",
    "    'seaborn',\n",
    "    'scikit-learn'\n",
    "}\n",
    "\n",
    "# Get the set of installed packages\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "# Determine which packages are missing\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    print(f\"Installing missing packages: {missing}\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *missing])\n",
    "else:\n",
    "    print(\"All required packages are already installed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Point\n",
    "from libpysal.weights import Queen\n",
    "from esda import Moran, Moran_Local\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from local file...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(data_path):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data from local file...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     crime_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path, usecols\u001b[38;5;241m=\u001b[39mcols)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading data from API...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_path = \"./data/NYPD_Complaint_Data_Historic_20250403.csv\"\n",
    "url = \"https://data.cityofnewyork.us/api/views/qgea-i56i/rows.csv?accessType=DOWNLOAD\"\n",
    "\n",
    "# columns to load\n",
    "cols = [\"CMPLNT_FR_DT\", \"LAW_CAT_CD\", \"BORO_NM\", \"ADDR_PCT_CD\", \"Latitude\", \"Longitude\"]\n",
    "\n",
    "# Check if the file exists locally\n",
    "if os.path.exists(data_path):\n",
    "    print(\"Loading data from local file...\")\n",
    "    crime_df = pd.read_csv(data_path, usecols=cols)\n",
    "else:\n",
    "    print(\"Downloading data from API...\")\n",
    "    crime_df = pd.read_csv(url, usecols=cols)\n",
    "    # Save the fetched data to a local CSV file for future use\n",
    "    crime_df.to_csv(data_path, index=False)\n",
    "\n",
    "# Convert dates to datetime. Parse errors will set value to NaT\n",
    "crime_df[\"CMPLNT_FR_DT\"] = pd.to_datetime(crime_df[\"CMPLNT_FR_DT\"], format=\"%m/%d/%Y\", errors='coerce')\n",
    "\n",
    "# Filter for year 2019\n",
    "crime_df = crime_df[crime_df[\"CMPLNT_FR_DT\"].dt.year == 2019]\n",
    "\n",
    "# Drop records with missing or invalid coordinates\n",
    "crime_df = crime_df.dropna(subset=[\"Latitude\", \"Longitude\"])\n",
    "crime_df = crime_df[crime_df[\"Latitude\"] != 0]\n",
    "\n",
    "print(f\"Total records in 2019: {len(crime_df)}\")\n",
    "crime_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amenities data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying OSM for amenities data...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'osmnx' has no attribute 'geometries_from_place'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 20\u001b[0m\n\u001b[0;32m     12\u001b[0m tags \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamenity\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestaurant\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleisure\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpark\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrailway\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Use OSMnx to query OSM for these features in New York City.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# You can adjust the place name to suit your area of interest.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m amenities_gdf \u001b[38;5;241m=\u001b[39m ox\u001b[38;5;241m.\u001b[39mgeometries_from_place(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew York City, USA\u001b[39m\u001b[38;5;124m\"\u001b[39m, tags)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Optional: Convert the geometry column to WKT (text) format so it can be saved to CSV\u001b[39;00m\n\u001b[0;32m     23\u001b[0m amenities_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m amenities_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m geom: geom\u001b[38;5;241m.\u001b[39mwkt \u001b[38;5;28;01mif\u001b[39;00m geom \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'osmnx' has no attribute 'geometries_from_place'"
     ]
    }
   ],
   "source": [
    "data_path_amenities = \"./data/NYC_Amenities.csv\"\n",
    "\n",
    "if os.path.exists(data_path_amenities):\n",
    "    print(\"Loading amenities data from local file...\")\n",
    "    amenities_df = pd.read_csv(data_path_amenities)\n",
    "else:\n",
    "    print(\"Querying OSM for amenities data...\")\n",
    "    # Define a dictionary of tags for the amenities you're interested in:\n",
    "    # - \"amenity\": bars and restaurants\n",
    "    # - \"leisure\": parks\n",
    "    # - \"railway\": stations\n",
    "    tags = {\n",
    "        \"amenity\": [\"bar\", \"restaurant\"],\n",
    "        \"leisure\": \"park\",\n",
    "        \"railway\": \"station\"\n",
    "    }\n",
    "    \n",
    "    # Use OSMnx to query OSM for these features in New York City.\n",
    "    # You can adjust the place name to suit your area of interest.\n",
    "    amenities_gdf = ox.geometries_from_place(\"New York City, USA\", tags)\n",
    "    \n",
    "    # Optional: Convert the geometry column to WKT (text) format so it can be saved to CSV\n",
    "    amenities_gdf['geometry'] = amenities_gdf['geometry'].apply(lambda geom: geom.wkt if geom is not None else None)\n",
    "    \n",
    "    # Save the queried data to a CSV file for future use\n",
    "    amenities_gdf.to_csv(data_path_amenities, index=False)\n",
    "    amenities_df = amenities_gdf\n",
    "    amenities_df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
